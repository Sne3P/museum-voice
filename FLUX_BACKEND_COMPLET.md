# ğŸ¨ Flux Backend Complet - Museum Voice

## ğŸ“‹ Vue d'ensemble

Le systÃ¨me Museum Voice suit un flux en 5 Ã©tapes pour transformer un PDF d'Å“uvre d'art en narrations audio personnalisÃ©es.

```
PDF â†’ MÃ©tadonnÃ©es â†’ Chunks â†’ Embeddings â†’ FAISS Index â†’ Narrations â†’ Audio
```

---

## ğŸ”„ Ã‰tapes dÃ©taillÃ©es

### 1ï¸âƒ£ **Upload & Extraction PDF**

**Endpoint:** `POST /api/extract-pdf-metadata`

**Processus:**
- Upload du PDF dans `/public/uploads/`
- Le backend accÃ¨de au fichier via volume Docker `uploads_data`
- `ModelCompliantPDFProcessor` extrait 10+ champs :
  - titre, artiste, date_oeuvre
  - materiaux, dimensions
  - mouvement, contexte_historique
  - description, analyse_technique
  - iconographie, anecdotes
  - reception_critique, provenance

**Fichier:** `backend/rag/model_pdf_processor.py`

**Sortie:** JSON avec mÃ©tadonnÃ©es structurÃ©es

---

### 2ï¸âƒ£ **Sauvegarde en Base de DonnÃ©es**

**Endpoint:** `POST /api/save-to-db`

**Processus:**
- CrÃ©ation/mise Ã  jour de l'Å“uvre dans table `oeuvres`
- Sauvegarde de toutes les mÃ©tadonnÃ©es
- Liaison avec artiste et mouvement (tables relationnelles)

**Fichier:** `app/api/save-to-db/route.ts`

**Base de donnÃ©es:** PostgreSQL 16 (Docker)

**Sortie:** `oeuvre_id` assignÃ©

---

### 3ï¸âƒ£ **CrÃ©ation des Chunks SÃ©mantiques**

**Endpoint:** `POST /api/chunks/create/<oeuvre_id>`

**Processus:**
- Segmentation sÃ©mantique des mÃ©tadonnÃ©es en **8 chunks** :
  1. **MÃ©tadonnÃ©es** (titre, artiste, date, matÃ©riaux)
  2. **Description** (description visuelle de l'Å“uvre)
  3. **Contexte historique** (commande, Ã©poque, circonstances)
  4. **Analyse technique** (technique picturale, matÃ©riaux, composition)
  5. **Iconographie** (symbolisme, signification)
  6. **RÃ©ception** (critique, importance historique)
  7. **Conservation** (Ã©tat, restaurations)
  8. **Provenance** (historique de possession)

- Chaque chunk = segment textuel cohÃ©rent (~200-500 caractÃ¨res)
- Sauvegarde dans table `chunk` avec `chunk_index`

**Fichier:** `backend/rag/traitement/chunk_creator_postgres.py`

**Sortie:** 6-8 chunks par Å“uvre (selon disponibilitÃ© mÃ©tadonnÃ©es)

---

### 4ï¸âƒ£ **GÃ©nÃ©ration d'Embeddings** âš ï¸ Ã€ IMPLÃ‰MENTER

**Endpoint futur:** `POST /api/embeddings/create/<oeuvre_id>`

**Processus prÃ©vu:**
- Pour chaque chunk : gÃ©nÃ©ration d'un vecteur d'embedding
- ModÃ¨le : Sentence Transformers (`all-MiniLM-L6-v2` ou Ã©quivalent)
- Dimension : 384 ou 768 (selon modÃ¨le)
- Sauvegarde dans table `embeddings`

**Fichier Ã  crÃ©er:** `backend/rag/embeddings/embedding_generator.py`

**Technologies:** 
- `sentence-transformers`
- `transformers` (HuggingFace)

---

### 5ï¸âƒ£ **Construction de l'Index FAISS** âš ï¸ Ã€ IMPLÃ‰MENTER

**Endpoint futur:** `POST /api/faiss/build/<oeuvre_id>` ou `/api/faiss/build-all`

**Processus prÃ©vu:**
- RÃ©cupÃ©ration de tous les embeddings
- Construction d'un index FAISS (IndexFlatL2 ou IndexIVFFlat)
- Sauvegarde de l'index sur disque (`indexes/artwork_{id}.faiss`)
- Permet recherche sÃ©mantique rapide

**Fichier Ã  crÃ©er:** `backend/rag/indexes/faiss_manager.py`

**Technologies:**
- `faiss-cpu` ou `faiss-gpu`
- Persistance sur volume Docker

---

### 6ï¸âƒ£ **PrÃ©gÃ©nÃ©ration des Narrations** âœ… IMPLÃ‰MENTÃ‰

**Endpoint:** `POST /api/pregenerate-artwork/<oeuvre_id>`

**Processus:**
- GÃ©nÃ©ration de **36 narrations** par Å“uvre :
  - **4 Ã¢ges** : enfant, ado, adulte, senior
  - **3 thÃ¨mes** : technique_picturale, biographie, historique
  - **3 styles** : analyse, decouverte, anecdote
  - **4 Ã— 3 Ã— 3 = 36 combinaisons**

- Pour chaque narration :
  1. SÃ©lection des chunks pertinents (selon thÃ¨me)
  2. GÃ©nÃ©ration du contenu Ã  partir des chunks rÃ©els
  3. Adaptation du ton selon l'Ã¢ge cible
  4. Application du style (analyse, dÃ©couverte, anecdote)
  5. Sauvegarde dans table `pregenerations`

**Fichier:** `backend/rag/pregeneration/simple_pregeneration_postgres.py`

**Exemple de sÃ©lection de chunks:**
- ThÃ¨me **technique_picturale** â†’ Chunks 1, 4 (mÃ©tadonnÃ©es, analyse technique)
- ThÃ¨me **biographie** â†’ Chunks 2, 3 (description, contexte)
- ThÃ¨me **historique** â†’ Chunks 3, 6, 7 (contexte, rÃ©ception, provenance)

**Sortie:** 36 textes uniques (~300-700 caractÃ¨res) sauvegardÃ©s en BDD

---

### 7ï¸âƒ£ **Conversion Text-to-Speech (TTS)** âš ï¸ Ã€ IMPLÃ‰MENTER

**Endpoint futur:** `POST /api/tts/generate/<pregeneration_id>` ou `/batch`

**Processus prÃ©vu:**
- Pour chaque narration : conversion texte â†’ audio
- Voix diffÃ©rentes selon Ã¢ge et contexte
- Format : MP3 ou WAV
- Sauvegarde dans `/public/audio/`
- Mise Ã  jour du champ `voice_link` dans `pregenerations`

**Technologies possibles:**
- **gTTS** (Google Text-to-Speech) - Gratuit, simple
- **Eleven Labs** - QualitÃ© professionnelle, payant
- **Azure Cognitive Services** - Multilingue, payant
- **Coqui TTS** - Open source, local

**Fichier Ã  crÃ©er:** `backend/rag/tts/tts_generator.py`

---

## ğŸ—„ï¸ Architecture Base de DonnÃ©es

### Tables principales

```sql
-- Å’uvres d'art
oeuvres (
    oeuvre_id SERIAL PRIMARY KEY,
    titre TEXT,
    artiste TEXT,
    date_oeuvre TEXT,
    materiaux TEXT,
    dimensions TEXT,
    mouvement TEXT,
    contexte_historique TEXT,
    description TEXT,
    analyse_technique TEXT,
    iconographie TEXT,
    anecdotes TEXT,
    reception_critique TEXT,
    provenance TEXT,
    ...
)

-- Chunks sÃ©mantiques
chunk (
    chunk_id SERIAL PRIMARY KEY,
    oeuvre_id INTEGER REFERENCES oeuvres,
    chunk_text TEXT,
    chunk_index INTEGER,
    chunk_type TEXT,
    created_at TIMESTAMP
)

-- PrÃ©gÃ©nÃ©rations
pregenerations (
    pregeneration_id SERIAL PRIMARY KEY,
    oeuvre_id INTEGER REFERENCES oeuvres,
    age_cible TEXT,           -- enfant | ado | adulte | senior
    thematique TEXT,          -- technique_picturale | biographie | historique
    style_texte TEXT,         -- analyse | decouverte | anecdote
    pregeneration_text TEXT,
    voice_link TEXT,
    created_at TIMESTAMP,
    updated_at TIMESTAMP,
    UNIQUE(oeuvre_id, age_cible, thematique, style_texte)
)

-- Embeddings (Ã  crÃ©er)
embeddings (
    embedding_id SERIAL PRIMARY KEY,
    chunk_id INTEGER REFERENCES chunk,
    vector VECTOR(384),       -- ou 768 selon modÃ¨le
    model_name TEXT,
    created_at TIMESTAMP
)
```

---

## ğŸ“‚ Structure Fichiers Backend

```
backend/rag/
â”œâ”€â”€ main_postgres.py              # API Flask principale
â”œâ”€â”€ model_pdf_processor.py        # Extraction PDF
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ db_postgres.py            # Connexion PostgreSQL
â”‚   â””â”€â”€ pregeneration_db.py       # Gestion prÃ©gÃ©nÃ©rations
â”‚
â”œâ”€â”€ traitement/
â”‚   â””â”€â”€ chunk_creator_postgres.py # CrÃ©ation chunks âœ…
â”‚
â”œâ”€â”€ pregeneration/
â”‚   â””â”€â”€ simple_pregeneration_postgres.py  # GÃ©nÃ©ration narrations âœ…
â”‚
â”œâ”€â”€ embeddings/                   # Ã€ CRÃ‰ER
â”‚   â””â”€â”€ embedding_generator.py
â”‚
â”œâ”€â”€ indexes/                      # Ã€ CRÃ‰ER
â”‚   â””â”€â”€ faiss_manager.py
â”‚
â””â”€â”€ tts/                          # Ã€ CRÃ‰ER
    â””â”€â”€ tts_generator.py
```

---

## ğŸ”Œ API Endpoints

### âœ… ImplÃ©mentÃ©s

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/extract-pdf-metadata` | POST | Extrait mÃ©tadonnÃ©es du PDF |
| `/api/artworks` | GET | Liste toutes les Å“uvres |
| `/api/artworks/<id>` | GET | DÃ©tails d'une Å“uvre |
| `/api/chunks/create/<oeuvre_id>` | POST | CrÃ©e chunks sÃ©mantiques |
| `/api/pregenerate-artwork/<id>` | POST | GÃ©nÃ¨re 36 narrations |
| `/api/pregenerate-all` | POST | GÃ©nÃ¨re pour toutes les Å“uvres |

### âš ï¸ Ã€ ImplÃ©menter

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/embeddings/create/<oeuvre_id>` | POST | GÃ©nÃ¨re embeddings des chunks |
| `/api/faiss/build/<oeuvre_id>` | POST | Construit index FAISS |
| `/api/faiss/search` | POST | Recherche sÃ©mantique |
| `/api/tts/generate/<pregen_id>` | POST | Convertit narration en audio |
| `/api/tts/batch/<oeuvre_id>` | POST | Convertit toutes narrations Å“uvre |

---

## ğŸ¯ Utilisation Typique

### Workflow complet pour une nouvelle Å“uvre

```bash
# 1. Upload PDF et extraction
POST /api/extract-pdf-metadata
{
  "pdfFile": <file>,
  "artworkId": 123
}

# 2. Sauvegarde en BDD (automatique depuis frontend)
POST /api/save-to-db
{
  "oeuvreId": 123,
  "metadata": { titre, artiste, ... }
}

# 3. CrÃ©ation des chunks
POST /api/chunks/create/123

# 4. (FUTUR) GÃ©nÃ©ration embeddings
POST /api/embeddings/create/123

# 5. (FUTUR) Construction index FAISS
POST /api/faiss/build/123

# 6. PrÃ©gÃ©nÃ©ration des narrations
POST /api/pregenerate-artwork/123
{
  "force_regenerate": false
}

# 7. (FUTUR) GÃ©nÃ©ration audio
POST /api/tts/batch/123
```

---

## ğŸ“Š Exemple de DonnÃ©es

### Artwork: "Paysage" - EugÃ¨ne Leroy (1982)

**MÃ©tadonnÃ©es extraites:** âœ…
```json
{
  "titre": "Paysage",
  "artiste": "EugÃ¨ne Leroy",
  "date_oeuvre": "1982",
  "materiaux": "Huile sur toile",
  "dimensions": "116 Ã— 89 cm",
  "mouvement": "Abstraction lyrique",
  "contexte_historique": "RÃ©alisÃ© en 1982...",
  "description": "La toile prÃ©sente une surface dense...",
  "analyse_technique": "Leroy utilise l'huile...",
  ...
}
```

**Chunks crÃ©Ã©s:** âœ… (6 chunks)
```
Chunk 1 (MÃ©tadonnÃ©es): "Titre : Paysage\nArtiste : EugÃ¨ne Leroy\nDate : 1982..."
Chunk 2 (Description): "La toile prÃ©sente une surface dense et Ã©paisse..."
Chunk 3 (Contexte): "Cette Å“uvre est rÃ©alisÃ©e en 1982, annÃ©e dÃ©cisive..."
Chunk 4 (Technique): "Leroy utilise l'huile de maniÃ¨re singuliÃ¨re..."
Chunk 5 (Iconographie): "Le paysage chez Leroy n'est pas une reprÃ©sentation..."
Chunk 6 (Provenance): "Non documentÃ©. Probablement collection privÃ©e."
```

**Narrations gÃ©nÃ©rÃ©es:** âœ… (36 narrations)
- Longueur moyenne: **436 caractÃ¨res**
- DiversitÃ©: **Contenu unique par profil**

Exemples:
```
[enfant | technique_picturale | analyse]
"Analyse : Bonjour ! Regarde bien ce tableau qui s'appelle Â« Paysage Â». 
Â« Paysage Â» de EugÃ¨ne Leroy. Titre : Paysage, Artiste : EugÃ¨ne Leroy, 
Date de crÃ©ation : 1982. Huile sur toile 116 Ã— 89 cm..."

[adulte | historique | analyse]
"Analyse : Â« Paysage Â» Cette Å“uvre est rÃ©alisÃ©e en 1982, annÃ©e dÃ©cisive 
dans la carriÃ¨re d'EugÃ¨ne Leroy. Elle coÃ¯ncide avec la premiÃ¨re grande 
rÃ©trospective de son travail, organisÃ©e par Jan Hoet au musÃ©e..."

[senior | biographie | decouverte]
"Ã€ la dÃ©couverte de cette Å“uvre : Cette Å“uvre remarquable, Â« Paysage Â» 
de EugÃ¨ne Leroy, mÃ©rite toute notre attention. EugÃ¨ne Leroy a crÃ©Ã© 
cette Å“uvre. Titre : Paysage, Artiste : EugÃ¨ne Leroy, Date de crÃ©ation : 1982..."
```

---

## ğŸš€ Prochaines ImplÃ©mentations

### 1. SystÃ¨me d'Embeddings

**Fichier:** `backend/rag/embeddings/embedding_generator.py`

```python
from sentence_transformers import SentenceTransformer

class EmbeddingGenerator:
    def __init__(self):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def generate_for_chunk(self, chunk_id: int):
        # RÃ©cupÃ¨re chunk
        # GÃ©nÃ¨re embedding
        # Sauvegarde en BDD
        pass
    
    def generate_for_artwork(self, oeuvre_id: int):
        # Pour tous les chunks de l'Å“uvre
        pass
```

**DÃ©pendance:** `pip install sentence-transformers`

---

### 2. Index FAISS

**Fichier:** `backend/rag/indexes/faiss_manager.py`

```python
import faiss
import numpy as np

class FAISSManager:
    def build_index(self, oeuvre_id: int):
        # RÃ©cupÃ¨re tous embeddings
        # CrÃ©e index FAISS
        # Sauvegarde sur disque
        pass
    
    def search(self, query_embedding, k=5):
        # Recherche les k chunks les plus proches
        pass
```

**DÃ©pendance:** `pip install faiss-cpu`

---

### 3. Text-to-Speech

**Fichier:** `backend/rag/tts/tts_generator.py`

```python
from gtts import gTTS

class TTSGenerator:
    def generate_audio(self, pregeneration_id: int):
        # RÃ©cupÃ¨re texte
        # GÃ©nÃ¨re MP3
        # Sauvegarde dans /public/audio/
        # Met Ã  jour voice_link
        pass
    
    def generate_batch(self, oeuvre_id: int):
        # Pour toutes les 36 prÃ©gÃ©nÃ©rations
        pass
```

**DÃ©pendance:** `pip install gTTS` ou `pip install elevenlabs`

---

## âœ… Ã‰tat Actuel vs Ã‰tat Futur

| FonctionnalitÃ© | Ã‰tat | Fichiers |
|----------------|------|----------|
| Extraction PDF | âœ… | `model_pdf_processor.py` |
| Sauvegarde BDD | âœ… | `db_postgres.py` |
| CrÃ©ation Chunks | âœ… | `chunk_creator_postgres.py` |
| Embeddings | âŒ | Ã€ crÃ©er |
| FAISS Index | âŒ | Ã€ crÃ©er |
| PrÃ©gÃ©nÃ©rations | âœ… | `simple_pregeneration_postgres.py` |
| TTS Audio | âŒ | Ã€ crÃ©er |
| RAG Dynamique | âŒ | NÃ©cessite embeddings + FAISS |

---

## ğŸ”’ Garanties

### âœ… Code Original PrÃ©servÃ©

Tous les fichiers SQLite originaux sont **INTACTS** :
- `backend/rag/db.py` âŒ NON MODIFIÃ‰
- `backend/rag/model_db.py` âŒ NON MODIFIÃ‰
- Autres fichiers SQLite âŒ NON MODIFIÃ‰S

### âœ… ImplÃ©mentation ParallÃ¨le

Nouveaux fichiers PostgreSQL crÃ©Ã©s **sÃ©parÃ©ment** :
- `backend/rag/core/db_postgres.py` âœ… NOUVEAU
- `backend/rag/core/pregeneration_db.py` âœ… NOUVEAU
- `backend/rag/traitement/chunk_creator_postgres.py` âœ… NOUVEAU
- `backend/rag/pregeneration/simple_pregeneration_postgres.py` âœ… NOUVEAU

---

## ğŸ“ Notes Importantes

1. **Volume Docker** : Le partage `uploads_data` entre `app` et `backend` est **CRITIQUE**
2. **Chunks sÃ©mantiques** : NÃ©cessaires pour des narrations riches et uniques
3. **36 narrations** : Couvrent tous les profils visiteurs
4. **Embeddings** : Prochaine Ã©tape pour RAG dynamique
5. **FAISS** : Permettra recherche sÃ©mantique et gÃ©nÃ©ration Ã  la volÃ©e
6. **TTS** : DerniÃ¨re Ã©tape pour audioguide complet

---

## ğŸ“ Conclusion

Le systÃ¨me actuel implÃ©mente **le cÅ“ur du pipeline** :
- PDF â†’ MÃ©tadonnÃ©es â†’ Chunks â†’ Narrations âœ…

Les **extensions futures** ajouteront :
- Embeddings â†’ FAISS â†’ RAG dynamique âš ï¸
- TTS â†’ Audio âš ï¸

Le design est **modulaire et Ã©volutif**, permettant d'ajouter ces fonctionnalitÃ©s sans casser l'existant.
